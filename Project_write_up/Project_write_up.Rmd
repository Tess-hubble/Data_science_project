---
title: "Predicting Total Auction Values in the Cape Colony"
documentclass: elsarticle
Thesis_FP: no
output:
  pdf_document:
    keep_tex: yes
    template: Tex/TexDefault.txt
    fig_width: 3.5
    fig_height: 3.5
  html_document:
    df_print: paged
Author1: Tessa Hubble
Ref1: Stellenbosch University, South Africa
Email1: 21559953\@sun.ac.za
BottomRFooter: \footnotesize Page \thepage
addtoprule: yes
addfootrule: yes
margin: 2.3
bottom: 2
top: 2.5
HardSet_layout: yes
linenumbers: no
bibliography: Tex/ref.bib
csl: "Tex/harvard-stellenbosch-university.csl"
RemovePreprintSubmittedTo: yes
Journal: Journal of Finance
toc: no
numbersections: yes
fontsize: 11pt
linestretch: 1.2
link-citations: yes
AddTitle: yes
abstract: |
  Predicting total auction values from a Cape Colony auction dataset between 1720 and 1820.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\data_loading.R")
source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\column_mutations.R")
source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\title_finders.R")

library(tidyverse)
library(ranger)
library(caret)
library(tidyr)
library(corrplot)
library(gridExtra)
library(broom)
library(huxtable)
library(ggplot2)
library(xtable)


# loading and merging data

purchases <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc_Purchases.csv") %>% select(mooc_id, buyer_id)
auctions <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc.csv") %>% 
    select(mooc_id, date, auction_tot) %>% 
    mutate(auction_tot= as.numeric(auction_tot)) 
final_df <- data_loader("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data")
merged_df <- merger(final_df, auctions) %>% 
    filter(unit_price>0)

    
# summing the number of items within a good type per auction 
goods <- c("books", "art_products", "balance", "beds", "cattle", "chairs", "china", "clocks", 
           "coatrack", "cups", "guns", "hammers", "horse_cart", "horses", "irons", "jewlery", 
           "lamps", "oven", "plates", "pot", "plough", "sheep", "slaves", "tables", 
                                                     "utensils", "wagons")
goods_id_str <- paste0("total_", goods)

total_number_good_auction <-  good_counter(goods = c("books", "art_products", "balance", 
                                                     "beds", "cattle", "chairs", "china", 
                                                     "clocks", "coatrack", "cups", "guns", 
                                                     "hammers", "horse_cart", "horses", "irons", 
                                                     "jewlery", "lamps", "oven", "plates", 
                                                     "pot", "plough", "sheep", "slaves", "tables", 
                                                     "utensils", "wagons")) %>% 
    distinct(mooc_id, .keep_all=TRUE) %>% 
    ungroup() %>% 
    dplyr::select(mooc_id, total_goods, goods_id) %>% 
    arrange(mooc_id) %>% 
    pivot_wider(names_from = goods_id, values_from = total_goods) %>% 
    as.data.frame() %>% 
    mutate(across(all_of(goods_id_str), ~ ifelse(is.na(.), 0, .)))

household_items <- c("beds", "chairs", "china", "clocks", "coatrack", "cups", "irons", "lamps", "tables", "balance")
kitchen_items <- c("oven", "plates", "pot", "utensils")
farming_items <- c("cattle", "sheep", "plough", "wagons", "horses", "horse_cart", "guns", "hammers")
select_items <- c("books", "jewelry", "slaves", "art_products")



# determining auction size

auction_size <- merged_df %>% 
        group_by(mooc_id) %>% 
    mutate(auction_size=sum(count)) %>% 
    distinct(mooc_id, .keep_all=TRUE) %>% 
    dplyr::select(mooc_id, date, auction_tot, auction_size) 

pen_ultimate_df <- left_join(total_number_good_auction, auction_size, "mooc_id")


# counting attendance by titled men and women per auction
women <- titledwomen_locator(titled_women, purchases$buyer_id) %>% 
    as.numeric()
men <- titledmen_locator(titled_men, purchases$buyer_id) %>% 
    as.numeric()
purchases_df <- tibble(purchases, women, men)
purchases_df <- title_counter(purchases_df) 
   

# merging titles and auctions
model_df <- inner_join(pen_ultimate_df,purchases_df, by="mooc_id")
model_df <- model_df %>% 
    mutate(year = substr(date, 1, 4)) %>% 
    arrange(year) %>% 
    group_by(year) %>% 
      mutate(date=n())

# assigning value from 1 to N for each year
model_df$date <- as.numeric(match(model_df$year, unique(model_df$year)))

# filtering table based on recording errors in year transcription
model_df <- model_df %>% 
    filter(date<103) %>% 
    filter(date!=1)  %>% 
    filter(auction_tot>0) %>% 
    filter(auction_tot!=-Inf)

# table for machine learning models
ml_df <- model_df %>% 
     ungroup() %>% 
    dplyr::select(-year, -mooc_id) %>% 
    na.omit() %>% 
  mutate(across(everything(), ~ifelse(. != 0, log(.), .)))
    

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

Over the first 150 years of the Cape Colony, deceased estate auctions were an important means of exchange for the burgeoning population. The only other means of purchasing goods was through ships that docked along the coast. From livestock and furniture to slaves, a wide variety of goods were obtained through auctions. Although auction rolls from this time period have been transcribed, inconsistent spelling and errors are pervasive. 30 different types of goods have been identified and tagged throughout the auction rolls. This project aims to use this subset of goods within auctions to predict total auction values. Focusing on approximately 1400 auctions between 1720 and 1820, two different machine learning techniques will be used to predict total auction values. Being able to assess the total auction value based on a subset of goods can be an important tool within historical data where there is limited information. Exploratory data analysis will provide context and support for the features included in the models. Throughout the exploratory data analysis and subsequent models, it becomes clear that the number of slaves, the date and the auction size consistently place upward pressure on total auction values.  The performance of a k-nearest neighbours model and random forest model are compared to that of a linear regression to assess accuracy.Ultimately, it is concluded that the subset of goods offer limited predictive power.

\newpage

# Auction data
Table 1 below provides an example of a portion of sales from one auction in 1770. This auction roll shows goods sold, the price and the type of good sold. A buyer_id column exists as well. Within this column, some names include titles such as "de Wede" (widow) or "mijnheer" (mister) which offers the possibility to determine how many titled men or women attend an auction. Table 1 shows that only a few goods are tagged.There are 26 different tagged goods in total. The number of different types of tagged goods per auction will act as predictors. It is therefore possible that the accuracy of the machine learning models included may be hampered by limited presence of these goods across auctions. 

```{r Table1,  warning =  FALSE, fig.align = 'center'}
auction_example <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc_Purchases.csv") %>% arrange(mooc_id) %>% 
    select(mooc_id, purchase_id, price, buyer_id, goods) %>% 
    filter(mooc_id=="MOOC10/10.1")
auction_example_goods <- data_auction("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data") %>% select(-bundle, -unit_price, -count) %>% mutate(year = substr(date, 1, 4))
auction_table <- full_join(auction_example, auction_example_goods, by = c("mooc_id", "purchase_id")) %>% 
    select(-date, -year, -buyer_id) %>% 
    arrange(purchase_id) %>% 
    filter(purchase_id< "MOOC10/10.1/20")

auction_tab <- options(xtable.comment=FALSE) %>% as.data.frame()
auction_tab <- xtable(auction_table)
auction_tab

```

# Exploratory Data Analysis

Figure 1 provides a scatter plot of the total auction values between 1720 and 1820. There is a general upwards trend in the value of auctions over time. However, a large proportion of auctions remain under 50 Rix-dollars (currency at the time). Grouping the goods according to household, kitchen, farming and select goods allows for the total auction value to be broken down according to a different collections of goods present at the auction. 

\newpage

```{r Figure1, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\ggplots.R")

#trying out plots 
trial_plots <- model_df %>% 
  filter(year >= 1720) %>% 
  mutate(time_period = ifelse(year > 1720 & year < 1730, "1720-1730", 
                              ifelse(year >= 1730 & year < 1740, "1730-1740", 
                                     ifelse(year >= 1740 & year < 1750, "1740-1750",
                                            ifelse(year >= 1750 & year < 1760, "1750-1760", 
                                                   ifelse(year >= 1760 & year < 1770, "1760-1770",
                                                          ifelse(year >= 1770 & year < 1780, "1770-1780",
                                                                 ifelse(year >= 1780 & year < 1790, "1780-1790",
                                                                        ifelse(year >= 1790 & year < 1800, "1790-1800", 
                                                                               ifelse(year >= 1800 & year < 1810, "1800-1810", 
                                                                                      ifelse(year >= 1810 & year < 1820, "1810-1820", NA))))))))))) %>% 
    filter(time_period!="NA")


# total auction value graph 
custom_breaks <- c(1720, 1740, 1760, 1780, 1800, 1820)
custom_labels <- c("1720", "1740", "1760", "1780", "1800", "1820")
trial_plots$year <- as.numeric(trial_plots$year)

total_auction <- timeline_plot(trial_plots)


total_auction

```

Figure 2 makes it clear that china, cups and chairs make up a large amount of the household goods sold per auction. However, the number of household goods, in absolute terms, does decline over time. 

```{r Figure2, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}

# plotting all goods
household_items <- c("beds", "chairs", "china", "clocks", "coatrack", "cups", "irons", "lamps", "tables", "balance")
household_items <- paste0("total_", household_items)
kitchen_items <- c("oven", "plates", "pot", "utensils")
kitchen_items <- paste0("total_", kitchen_items)
farming_items <- c("cattle", "sheep", "plough", "wagons", "horses", "horse_cart", "guns", "hammers")
farming_items <- paste0("total_", farming_items)
select_items <- c("books", "slaves", "art_products")
select_items <- paste0("total_", select_items)

# household goods

all_goods_household <- trial_plots %>% 
    select(mooc_id, year, time_period, household_items) %>% 
    group_by(time_period) %>% 
    summarise(total_beds=mean(total_beds), 
              total_chairs=mean(total_chairs), 
              total_china=mean(total_china), 
              total_clocks=mean(total_clocks), 
              total_coatrack=mean(total_coatrack), 
              total_cups=mean(total_cups), 
              total_irons=mean(total_irons), 
              total_lamps=mean(total_lamps), 
              total_tables=mean(total_tables), 
              total_balance=mean(total_balance)) %>% 
        gather(household_goods, value, household_items) %>% 
    ungroup()


household_goods <- ggplot(all_goods_household, aes(x=time_period, y=value, fill= household_goods)) +
    geom_bar(stat="identity")+
    scale_fill_manual(values = c("#FFB400", "#FFC740", "#C20008", "#FF020D", "#13AFEF", "#009944", "#8C4799", "#FF6600", "#A6BDDB", "#00B33C"))+
     labs(title = "Number of houshold goods per auction over time",
       x = "Year", y = "Number of household goods per auction", 
       fill = "Household goods")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
household_goods


```

Figure 3 shows that utensils and plates make up the largest amount of kitchen goods sold per auction. As with household goods, kitchen goods also decline in absolute terms over time. 

```{r Figure3, warning=FALSE, message=FALSE, results='hide', echo=FALSE,  fig.align = 'center'}
# kitchen items 

all_goods_kitchen <- trial_plots %>% 
    select(mooc_id, year, time_period, kitchen_items) %>% 
    group_by(time_period) %>% 
    summarise(total_oven=mean(total_oven), 
              total_plates=mean(total_plates), 
              total_pot=mean(total_pot), 
              total_utensils=mean(total_utensils)) %>% 
        gather(kitchen_goods, value, kitchen_items) %>% 
    ungroup()

kitchen_goods <- ggplot(all_goods_kitchen, aes(x=time_period, y=value, fill= kitchen_goods)) +
    geom_bar(stat="identity")+
    scale_fill_manual(values = c("#FFB400", "#FFC740", "#C20008", "#FF020D"))+
     labs(title = "Number of kitchen goods per auction over time",
       x = "Year", y = "Number of kitchen goods per auction", 
       fill = "Kitchen goods") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
kitchen_goods


```

Figure 4 shows that the total number of farming goods is much higher than that of household and kitchen goods which peak at 200 and 120, respectively. Cattle and sheep are the most prominent farming goods sold per auction. 

```{r Figure4, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
# farming items

all_goods_farm <- trial_plots %>% 
    select(mooc_id, year, time_period, farming_items) %>% 
    group_by(time_period) %>% 
    summarise(total_cattle=mean(total_cattle), 
              total_sheep=mean(total_sheep), 
              total_plough=mean(total_plough), 
              total_wagons=mean(total_wagons), 
              total_horses=mean(total_horses), 
              total_horse_cart=mean(total_horse_cart), 
              total_guns=mean(total_guns), 
              total_hammers=mean(total_hammers)) %>% 
        gather(farming_goods, value, farming_items) %>% 
    ungroup()

farming_goods <- ggplot(all_goods_farm, aes(x=time_period, y=value, fill= farming_goods)) +
    geom_bar(stat="identity")+
    scale_fill_manual(values = c("#FFB400", "#FFC740","#8C4799" , "#FF020D", "#13AFEF", "#009944","#C20008" , "#FF6600"))+ 
     labs(title = "Number of farming goods per auction over time",
       x = "Year", y = "Number of farming goods per auction", 
       fill = "Farming goods") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
farming_goods



```

Figure 5 shows the average number of art products, books and slaves sold per auction over time. The absolute number of select goods is lower than the number of household, kitchen and farming goods. The umber of select goods per auction is more consistent over time than the other collections of goods.

```{r Figure5, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
# select items

all_goods_select <- trial_plots %>% 
    select(mooc_id, year, time_period, select_items) %>% 
    group_by(time_period) %>% 
    summarise(total_books=mean(total_books),
              total_slaves=mean(total_slaves), 
              total_art_products=mean(total_art_products)) %>% 
        gather(select_goods, value, select_items) %>% 
    ungroup()

select_goods <- ggplot(all_goods_select, aes(x=time_period, y=value, fill= select_goods)) +
    geom_bar(stat="identity")+
    scale_fill_manual(values = c("#FFB400", "#C20008", "#FF020D"))+
     labs(title = "Number of select goods per auction over time",
       x = "Year", y = "Number of select goods", 
       fill = "Select goods") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

select_goods
```

The figures above indicate that the following goods the most frequently appear per auction: china, plates, utensils, sheep cattle, books, slaves and art products. Figure 6 shows box plots for some of these frequently purchased good types. For visual purposes, the y-axis was capped at 200 but there are a few outliers exceeding this number. Cattle and utensils appear to be some of the most frequently purchased goods throughout auctions yet the average number of goods per auction for each type remains very low. 

```{r Figure6, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
 
# focus on 5 most common goods and how bundle changes over time 

big_five_df <- model_df %>% 
  filter(year >= 1720) %>% 
  mutate(time_period = ifelse(year > 1720 & year < 1755, "1720-1755", 
                              ifelse(year >= 1755 & year < 1790, "1755-1790", 
                                     ifelse(year >= 1790 & year < 1820, "1790-1820", "NA"))))%>% filter(time_period!="NA") %>% 
    dplyr::select(time_period, total_cattle, total_sheep, total_horses, total_slaves, total_utensils) %>% 
    gather(good, value, total_cattle, total_sheep, total_horses, total_slaves, total_utensils) %>% 
    filter(value<200)
    
big_five_boxplots <- ggplot(big_five_df, aes(x = time_period, y = value, fill = good)) +
  geom_boxplot() +
  facet_wrap(~time_period, scales = "free_x") +
  labs(title = "Boxplots of the most frequently purchased goods by time period",
       x = "Time Period",
       y = "Number of purchases",
       fill = "Good type") +
      scale_fill_manual(values = c("#FFB400", "#FFC740", "#C20008", "#FF020D", "#13AFEF")) 
    theme_minimal()+
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"),
        axis.text.x = element_blank())

big_five_boxplots

    
```

In terms of attendance by titled men and women, Figure 7 shows the trends over time. There is a downward trend in attendance by titled purchasers from 1750 onwards and titled men always outnumber titled women at auctions. Although this univariate analysis identifies potentially important good types, their relationship with auction total values is more important. 

```{r Figure7, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
# attendance

attendance_df <-  model_df %>% 
  filter(year >= 1720) %>% 
  mutate(time_period = ifelse(year > 1720 & year < 1730, "1720-1730", 
                              ifelse(year >= 1730 & year < 1740, "1730-1740", 
                                     ifelse(year >= 1740 & year < 1750, "1740-1750",
                                            ifelse(year >= 1750 & year < 1760, "1750-1760", 
                                                   ifelse(year >= 1760 & year < 1770, "1760-1770",
                                                          ifelse(year >= 1770 & year < 1780, "1770-1780",
                                                                 ifelse(year >= 1780 & year < 1790, "1780-1790",
                                                                        ifelse(year >= 1790 & year < 1800, "1790-1800", 
                                                                               ifelse(year >= 1800 & year < 1810, "1800-1810", 
                                                                                      ifelse(year >= 1810 & year < 1820, "1810-1820", NA))))))))))) %>% 
    filter(time_period!="NA") %>% 
    group_by(time_period) %>% 
    summarise(women=mean(women_tot), 
              men=mean(men_total)) %>% 
    gather(attendance, number, women, men)
attendance_df$number <- as.numeric(attendance_df$number)


attendance_plot <- ggplot(attendance_df, aes(x = time_period, y = number, fill = attendance)) +
  geom_bar(stat = "identity", position = "stack")+
      labs(title = "Average attendance by titled men and women over time",
       x = "Time Period",
       y = "Average attendance",
       fill = "Titled") +
  scale_fill_manual(values = c("#FFC740", "#C20008")) +
  theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

attendance_plot
```

Figure 8 shows how certain good type purchases relate to total auction values. This shows that the data is heavily clustered close to 0 due to the small number of tagged goods present at each auction. 

```{r Figure8, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
# bivariate analysis 

source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\ggplots.R")

auction_size <- scatter_plotter(trial_plots$auction_size, "Auction values vs auction\n size","Auction size")
cattle <- scatter_plotter(trial_plots$total_cattle, "Auction values vs cattle\n purchases","Total number of cattle\n purhased per auction")
slaves <- scatter_plotter(trial_plots$total_slaves, "Auction values vs slave\n purchases","Total number of slaves\n purhased per auction")
sheep <- scatter_plotter(trial_plots$total_sheep, "Auction values vs sheep\n purchases","Total number of sheep\n purhased per auction")
horses <- scatter_plotter(trial_plots$total_horses, "Auction values vs horse\n purchases","Total number of horses\n purhased per auction")
men <- scatter_plotter(trial_plots$men_total, "Auction values vs titled\n men attendance","Total number of titled\n men per auction")

bivariat_plot <- grid.arrange(auction_size, cattle, slaves, sheep, horses, men, ncol = 3, nrow = 2)

bivariat_plot

```

# Target and feature engineering

The target in this project is the auction total value. The features used to predict the target include:
the total number of items within a good type per auction, total number of items within an auction (auction size), number of titled men and women in attendance per auction and the year of auction.  Figure 9 provides evidence that the features are skewed left. This is solved by applying a log transformation to all features (except for the date). 

```{r Figure9,  warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}
source("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\code\\ggplots.R")


auction_unlogged <- unlogged_distribution(model_df$auction_tot, "Distribution of total auction values", "Total auction value")
auction_logged <- model_df %>% mutate(auction_tot=log(auction_tot)) %>% 
     ggplot(aes(x=auction_tot))+
    geom_density()+
    labs(title = "Distribution of logged\n total auction values",
         x = "Logged total auction value", y = "Density") +
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"))
cattle_unlogged <- unlogged_distribution(model_df$total_cattle, "Distribution of number\n of cattle purchases", "Total cattle purchases per auction")
cattle_logged <- model_df %>% mutate(cattle=log(total_cattle)) %>% 
     ggplot(aes(x=cattle))+
    geom_density()+
    labs(title = "Distribution of logged\n cattle purchases",
         x = "Logged cattle purchases\n per auction", y = "Density") +
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"))
men_attend_unlogged <- unlogged_distribution(model_df$men_total, "Distribution of titled\n men auction attendance", "Titled men attendance\n per auction")
men_attend_logged <- model_df %>% mutate(men_total=log(men_total)) %>% 
     ggplot(aes(x=men_total))+
    geom_density()+
    labs(title = "Distribution of logged\n titled men attendance",
         x = "Logged titled men\n attendance per auction", y = "Density") +
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face="bold"))

distribution_plots <- grid.arrange(auction_unlogged, auction_logged, cattle_unlogged, cattle_logged, men_attend_unlogged, men_attend_logged, ncol = 2, nrow = 3)
    
distribution_plots
```


# Methodology

This project aims to predict auction values based on different types of goods present at an auction. Predicting a continuous, numerical value presents a regression problem. As a result, the k-Nearest Neighbours (KNN) model and a random forest model will be used. A linear regression model will be used to determine how well machine learning models compare to a regression. The metric used to assess the quality of the machine learning predictions will be root-mean-squared-error (RMSE). This metric indicates how far predictions are from actual values on average. Additionally, r^2 will be used to determine how well the model fits the data. A default model will be run for each model before conducting hyperparameter tuning to improve the model. 

# KNN model

The KNN model generates predictions for a new observation based on matching it to the most similar training observations and aggregating their values. When assessing a new observation (auction), it will compare the bundle of goods present to other auctions with the most similar bundles of goods sold and average their total values to determine a prediction. Hyperparameter tuning is required to set the optimal value of k. Figure 10 shows that k=5 is the optimal value. New observations predictions will be the average of its five most similar auctions. 

```{r Figure10, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.width=6, fig.height=5, fig.align = 'center'}
# testing and training 
set.seed(123)
indices <- sample(nrow(ml_df))
train_size <- floor(0.6 * nrow(ml_df))
training_data <- ml_df[indices[1:train_size], ]
testing_data <- ml_df[indices[(train_size + 1):nrow(ml_df)], ]


# knn
sampling_strat <- caret::trainControl(
    method="repeatedcv", 
    number=10, 
    repeats=5
)

hyper_grid <- expand.grid(k = seq(1, 25, by = 1))

knn_fit <- train(
  auction_tot ~ ., 
  data = training_data, 
  method = "knn", 
  trControl = sampling_strat, 
  tuneGrid = hyper_grid,
  metric = "RMSE"
)


knn_plot <- ggplot(knn_fit)+
    labs(title= "Optimal k-value", 
         x="Neighbours")+
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
knn_plot




```

With the training data set, RMSE is 1.35 and r^2 is 0.59. When the model uses the testing data,however, RMSE reduces to 1.17 and r^2 increases to 0.83. This would indicate that the predictive accuracy and model fit improved between the training and testing data. It is important to note that it is a problem that RMSE decreases and r^2 increases when moving from the training to the testing dataset. One would expect to see the opposite. Possible reasons for this may include data leakage. After checking for this, I could not come to an explanation for why this was occurring.The mean logged auction total is 6.32 which means that the average difference between predictions and actual values is 1.35. As a proportion of the mean total auction value, this figure is quite large. Figure 11 shows that a very small proportion of predictions are within 0.3 points of the actual value. This indicates that knn is a poor model for predicting total auction values.   


```{r Fgiure11, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}

# Train the KNN model with the chosen k value
k <- 5
knn_model <- train(
  auction_tot ~ .,
  data = training_data,
  method = "knn",
  trControl = sampling_strat,
  tuneGrid = data.frame(k = k),
  metric = "RMSE"
)

# k = 5 has the lowest RMSE
# RMSE = 1.345573  Rsquared = 0.5987131 MAE = 0.9381762  

# Make predictions on the testing data
predictions_knn <- predict(knn_model, newdata = testing_data)
RMSE(predictions_knn, testing_data$auction_tot) # 1.17
MAE(predictions_knn, testing_data$auction_tot) # 0.83
R2(predictions_knn, testing_data$auction_tot) # r-squared: 0.66

# plot
prediction_knn_df <- data.frame(
  Actual = testing_data$auction_tot,
  Predicted = predictions_knn
) 
prediction_knn_df <- prediction_knn_df %>% 
    mutate(Accuracy= ifelse(abs(Predicted-Actual)<0.1, "Within 0.1 of predicted value", 
                            ifelse(abs(Predicted-Actual)<0.2, "Within 0.2 of predicted value", 
                                   ifelse(abs(Predicted-Actual)<0.3, "Within 0.3 of predicted value", 
                                          "More than 0.3 from predicted value"))))

knn_predictions_plot <- ggplot(prediction_knn_df, aes(x = Actual, y = Predicted, colour=Accuracy)) +
  geom_point() +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = "knn model: predictions vs actual values", x = "Actual", y = "Predicted")+
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

knn_predictions_plot
```

# Random Forest Model

Random forest models include multiple decision trees to make predictions. Decision trees are built independently on a subset of data to introduce diversity among trees and reduce overfitting. Additionally, random features are selected at each node of the tree to cover a wider breadth of the data and include more robust predictions. Once the decision trees are trained, predictions of each tree are aggregated to generate predictions. The randomness of data and feature selection decreases variance in predictions and aggregating tree-level predictions minimises bias introduced within trees. Tuning parameters such as the number of trees within the random forest and the number of features randomly selected at each node should improve predictions. Furthermore, the node size can also be tuned as it refers to the minimum number of observations required at a terminal node to ensure another split.

The default model includes 500 trees, 10 features randomly selected at each split and a target node size of 10. The RMSE is 1.1 and the r^2 is 0.73. A random forest model offers information on each features' importance in generating predictions. It is clear from Figure 12 that the number of slaves at an auction is the most important feature, followed by the size of the auction, the year the auction took place and the number of titled men in attendance. These features make sense within the context of the Cape Colony.


```{r Figure12, , warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}

n_features <- length(setdiff(names(training_data), "auction_tot"))


# train a default random forest model
training_rf <- ranger(
  auction_tot ~ ., 
  data = training_data,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  importance= "permutation",
  seed = 123
)

default_rmse <- sqrt(training_rf$prediction.error) # RMSE: 0.94
rf_importance <- ranger::importance(training_rf)


# importance plot

rf_importance_df <- data.frame(
    Importance = training_rf[["variable.importance"]]
) %>% rownames_to_column() %>% arrange(desc(Importance))
colnames(rf_importance_df) <- c("Feature", "Importance")


importance_plot <- ggplot(rf_importance_df, aes(x= reorder(Feature, -Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "#C20008") +
  labs(title = "Feature Importance", x = "Feature", y = "Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=7))+
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"))

importance_plot
```

After completing a grid search to tune parameters, the default model is found to perform the best. When moving from the training to the testing data, RMSE increases to 2.68. Figure 13 below shows that only a small proportion of predictions are within 0.1 of the predicted value. Based on RMSE scores, the knn model performs better than the random forest model as its RMSE is 1.17. 

```{r Figure13, warning=FALSE, message=FALSE, results='hide', echo=FALSE, fig.align = 'center'}

# parameter grid
#parameter_grid <- expand.grid(
#  mtry = c(floor(n_features / 3)),
#  num.trees = c(100, 300, 500),
#  min.node.size = c(1, 5, 10))

#results <- lapply(1:nrow(parameter_grid), function(i) {
#  model <- ranger(
#    auction_tot ~ .,
#    data = training_data,
#    num.trees = parameter_grid$num.trees[i],
#    mtry = parameter_grid$mtry[i],
#    min.node.size = parameter_grid$min.node.size[i],
#    respect.unordered.factors = "order",
#    importance = "permutation",
#    seed = 123
#  )
#  predictions <- predict(model, data = testing_data)$predictions
#  rmse <- sqrt(mean((predictions - testing_data$auction_tot)^2))
#  list(model = model, rmse = rmse)
#})

#best_model_index <- which.min(sapply(results, function(x) x$rmse))
#best_model <- results[[best_model_index]]$model

#train_predictions <- predict(best_model, data = training_data)$predictions
#rmse_train <- sqrt(mean((train_predictions - training_data$auction_tot)^2)) # RMSE: 0.68

# baseline model is the best

default_predictions <- predict(training_rf, data = testing_data)$predictions
rmse_default_test <- sqrt(mean((default_predictions - training_data$auction_tot)^2)) # 2.68


# plot
rf_predictions <- data.frame(
  Actual = testing_data$auction_tot,
  Predictions = default_predictions
) %>% 
    mutate(Accuracy= ifelse(abs(Predictions-Actual)<0.1, "Within 0.1 of predicted value", 
                            ifelse(abs(Predictions-Actual)<0.2, "Within 0.2 of predicted value", 
                                   ifelse(abs(Predictions-Actual)<0.3, "Within 0.3 of predicted value", 
                                          "More than 0.3 from predicted value"))))

rf_plot <- ggplot(rf_predictions, aes(x = Actual, y = Predictions, color = Accuracy)) +
  geom_point() +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(title = "Random forest: predictions vs actual Values", x = "Actual", y = "Predicted")+
    theme(plot.title = element_text(hjust = 0.5, vjust = 2, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

rf_plot 

```

# Linear regression

A linear regression is shown below. The RMSE is 1.13 and the r^2 is 0.71. This linear regression model therefore performs better than the machine learning models with a higher prediction accuracy and better fit. 

```{r}
reg <- lm(auction_tot ~ ., data = ml_df)


# comparison
residuals <- reg$residuals
rmse <- sqrt(mean(residuals^2)) # 1.13
r_squared <- summary(reg)$r.squared # 0.71
```

# Critiques 

Although the linear regression performed better than the knn and random forest model, all three models have low predictive accuracy. It is clear that the subset of goods used to predict total auction values, are insufficient predictors of total auction values. 

# Conclusion

Predicting total auction value using a subset of goods present at auctions resulted in very inaccurate models. The knn and random forest models were tested and performed poorly given the constraints presented by the features chosen. This highlights the importance of choosing appropriate features when using using machine learning techniques. 


