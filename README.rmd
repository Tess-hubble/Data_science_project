---
output:
  md_document:
    variant: markdown_github
---

# Purpose

Purpose of this work folder.

Ideally store a minimum working example data set in data folder.

Add binary files in bin, and closed R functions in code. Human Readable settings files (e.g. csv) should be placed in settings/


```{r}


library(randomForest)
library(caret)


# loading and merging data
purchases <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc_Purchases.csv") %>% select(mooc_id, buyer_id)
auctions <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc.csv") %>% select(mooc_id, date, auction_tot)
final_df <- data_loader("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data")
merged_df <- merger(final_df)



# counting total number of good types per auction 
merged_df <- merged_df %>% group_by(mooc_id) %>% mutate(number_bundles=sum(bundle))%>% separate(date, into =c('year', 'month/day'), sep=4)
merged_df <- good_counter(merged_df, c("books", "art_products", "scales", "beds", "cattle", "chairs", "china", "coatrack", "cups", "guns", "hammers", "horse_cart", "horses", "irons", "jewelry", "lamps", "oven", "plates", "pot", "sheep", "slaves", "tables", "utensils", "wagons"), c("book_tot", "art_tot", "scale_tot", "bed_tot", "cattle_tot", "chairs_tot", "china_tot", "coatrack_tot", "cup_tot", "guns_tot", "hammer_tot", "horsecart_tot", "horse_tot", "irons_tot", "jewelry_tot", "lamp_tot", "oven_tot", "plates_tot", "pot_total", "sheep_tot", "slave_tot", "table_tot", "utensil_tot", "wagon_tot" )) 
merged_df <- merged_df %>% distinct(mooc_id, .keep_all=TRUE)

# counting attendance by titled men and women per auction
women <- titledwomen_locator(titled_women, purchases$buyer_id)
men <- titledmen_locator(titled_men, purchases$buyer_id)
purchases_df <- tibble(purchases, women, men)
purchases_df <- purchases_df %>% group_by(mooc_id) %>% 
    mutate(women_tot=sum(women, na.rm=TRUE)) %>% mutate(men_total=sum(men, na.rm=TRUE)) %>% 
    select(mooc_id, women_tot, men_total) %>% 
    distinct(mooc_id, .keep_all=TRUE)
### title_counter("women_tot", "women")

# merging titles and auctions
merged_df <- inner_join(merged_df,purchases_df, by="mooc_id") %>% select(-`month/day`, type)
merged_df <- merged_df %>%  
    arrange(year) %>% 
    group_by(year) %>% 
    mutate(date=n())
merged_df$date <- as.numeric(match(merged_df$year, unique(merged_df$year)))
merged_df <- merged_df %>% filter(date<103) %>% filter(date!=1) %>% na.omit() 
merged_df$auction_tot <- as.numeric(merged_df$auction_tot)
merged_df <- merged_df %>% ungroup() %>% select(-mooc_id, -type, -year, -bundle) %>% 
    filter(auction_tot>60)



```
# descriptives
```{r}

Mean_auction_total <- mean(merged_df$auction_tot)
sd_auction_total <- sd(merged_df$auction_tot)
merged_df <- merged_df %>%
    mutate(z_score=((auction_tot-Mean_auction_total)/sd_auction_total)) %>% 
    ungroup() %>% 
    arrange(z_score) %>% 
    filter(z_score<5) 


auction_timeline <- plotter(merged_df, auction_plot, merged_df$year, merged_df$auction_tot)

```


# splitting into testing and training
```{r}
library(caret)

# splitting into testing and trainging 
set.seed(123)
indices <- sample(nrow(merged_df))
train_size <- floor(0.6 * nrow(merged_df))
training_data <- merged_df[indices[1:train_size], ]
testing_data <- merged_df[indices[(train_size + 1):nrow(merged_df)], ]

```

# resampling methods
```{r}

sampling_strat <- caret::trainControl(
    method="repeatedcv", 
    number=10, 
    repeats=5
)

hyper_grid <- expand.grid(k = seq(2, 25, by = 1))

knn_fit <- train(
  auction_tot ~ ., 
  data = training_data, 
  method = "knn", 
  trControl = sampling_strat, 
  tuneGrid = hyper_grid,
  metric = "RMSE"
)
    
ggplot(knn_fit)
# k = 2 has the lowest RMSE

library(caret)

# Train the KNN model with the chosen k value
k <- 2
knn_model <- train(
  auction_tot ~ .,
  data = training_data,
  method = "knn",
  trControl = sampling_strat,
  tuneGrid = data.frame(k = k),
  metric = "accuracy"
)
knn_model
# Make predictions on the testing data
predictions <- predict(knn_model, newdata = testing_data)



```

# random forest
```{r}
library(ranger)

dim(merged_df)
n_features <- length(setdiff(names(training_data), "auction_tot"))

# train a default random forest model
training_rf <- ranger(
  auction_tot ~ ., 
  data = training_data,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  importance= "permutation",
  seed = 123
)
training_rf
default_rmse <- sqrt(training_rf$prediction.error)
rf_importance <- ranger::importance(training_rf)
sort(rf_importance, decreasing = TRUE)

# Predict auction total values
predictions_rf <- predict(training_rf, data = testing_data)$predictions

plot(training_data$auction_tot, training_rf$predictions)

```


```{r}
model <- randomForest(auction_tot ~ . , data = training_data)
predictions <- predict(model, newdata = testing_data)
predictions
mean(abs(predictions - testing_data$auction_tot))
# Calculate Mean Squared Error
MSE <- mean((predictions - testing_data$auction_tot)^2)
SSR <- sum((predictions - mean(testing_data$auction_tot))^2)
SST <- sum((testing_data$auction_tot - mean(testing_data$auction_tot))^2)
R_squared <- SSR / SST
mean(predictions == testing_data$auction_tot)



```



