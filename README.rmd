---
output:
  md_document:
    variant: markdown_github
---

# Purpose

Proposed layout: EDA (univariate, bivariate analysis), model (compare hard to interpret results against bivariate)

```{r}

library(tidyverse)
library(randomForest)
library(caret)
library(tidyr)


# loading and merging data

art <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\priceseries_art_products_purch_rec.csv")
purchases <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc_Purchases.csv") %>% select(mooc_id, buyer_id)
auctions <- read_csv("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data\\Full_Rec_Mooc.csv") %>% 
    select(mooc_id, date, auction_tot) %>% 
    mutate(auction_tot= as.numeric(auction_tot)) %>% 
    mutate(auction_tot = log(auction_tot))
final_df <- data_loader("C:\\Users\\tessa\\OneDrive\\Desktop\\Masters 2023\\Data science\\Project\\data")
merged_df <- merger(final_df, auctions) %>% 
    filter(unit_price>0)
       

# summing total purchase value of all the items within a good type at an auction 
goods <- c("books", "art_products", "balance", "beds", "cattle", "chairs", "china", "clocks", 
           "coatrack", "cups", "guns", "hammers", "horse_cart", "horses", "irons", 
           "jewlery", "lamps", "oven", "plates", "pot", "plough", "sheep", "slaves", "tables", 
           "utensils", "wagons")
total_value_good_auction <- total_purchase_value(goods = c("books", "art_products", "balance", 
                                                           "beds", "cattle", "chairs", "china", 
                                                           "clocks", "coatrack", "cups", "guns", 
                                                           "hammers", "horse_cart", "horses", "irons", 
                                                           "jewlery", "lamps", "oven", "plates", 
                                                           "pot", "plough", "sheep", "slaves", "tables", 
                                                           "utensils", "wagons")) %>% 
    spread(key = type, value = total_value, fill = 0) 
    
# summing the number of items within a good type per auction 

goods_id_str <- paste0("total_", goods)

total_number_good_auction <-  good_counter(goods = c("books", "art_products", "balance", 
                                                     "beds", "cattle", "chairs", "china", 
                                                     "clocks", "coatrack", "cups", "guns", 
                                                     "hammers", "horse_cart", "horses", "irons", 
                                                     "jewlery", "lamps", "oven", "plates", 
                                                     "pot", "plough", "sheep", "slaves", "tables", 
                                                     "utensils", "wagons")) %>% 
    distinct(mooc_id, .keep_all=TRUE) %>% 
    ungroup() %>% 
    dplyr::select(mooc_id, total_goods, goods_id) %>% 
    arrange(mooc_id) %>% 
    pivot_wider(names_from = goods_id, values_from = total_goods) %>% 
    as.data.frame() %>% 
    mutate(across(all_of(goods_id_str), ~ ifelse(is.na(.), 0, .)))

# determining auction size

auction_size <- merged_df %>% 
        group_by(mooc_id) %>% 
    mutate(auction_size=sum(count)) %>% 
    distinct(mooc_id, .keep_all=TRUE) %>% 
    dplyr::select(mooc_id, date, auction_tot, auction_size)

interim_df <- left_join(total_value_good_auction, total_number_good_auction, "mooc_id")
pen_ultimate_df <- left_join(interim_df, auction_size, "mooc_id")


# counting attendance by titled men and women per auction
women <- titledwomen_locator(titled_women, purchases$buyer_id) %>% 
    as.numeric()
men <- titledmen_locator(titled_men, purchases$buyer_id) %>% 
    as.numeric()
purchases_df <- tibble(purchases, women, men)
purchases_df <- title_counter(purchases_df)


# merging titles and auctions
model_df <- inner_join(pen_ultimate_df,purchases_df, by="mooc_id") %>% 
    mutate(year = substr(date, 1, 4)) %>% 
    arrange(year) %>% 
    group_by(year) %>% 
      mutate(date=n())

# assigning value from 1 to N for each year
model_df$date <- as.numeric(match(model_df$year, unique(model_df$year)))

# filtering table based on recording errors in year transcription
model_df <- model_df %>% 
    filter(date<103) %>% 
    filter(date!=1)  %>% 
    filter(auction_tot>0) %>% 
    filter(auction_tot!=-Inf)


```

# descriptives
```{r}

Mean_auction_total <- mean(model_df$auction_tot)
sd_auction_total <- sd(model_df$auction_tot)

summary(model_df)

ggplot(model_df, aes(x=year, fill=total_slaves))+
    geom_density()

auction_timeline <- plotter(model_df, model_df$year, model_df$auction_tot, "Total auction value")

attendance_plotter(attendance_df, attendance_df$year, attendance_df$number, filler=attendance_df$title)

slave_purchases <- plotter(plotting_df$slave_tot,"Total number of slaves sold per auction", "Number")
wagon_purchases <- plotter(plotting_df$wagon_tot,"Total number of wagons sold per auction", "Number")
horse_purchases <- plotter(plotting_df$horse_tot,"Total number of horses sold per auction", "Number")

## univariate analysis 


```


# splitting into testing and training
```{r}
library(caret)

# splitting into testing and trainging 
set.seed(123)
indices <- sample(nrow(merged_df))
train_size <- floor(0.6 * nrow(merged_df))
training_data <- merged_df[indices[1:train_size], ]
testing_data <- merged_df[indices[(train_size + 1):nrow(merged_df)], ]

```

# knn method
```{r}

sampling_strat <- caret::trainControl(
    method="repeatedcv", 
    number=10, 
    repeats=5
)

hyper_grid <- expand.grid(k = seq(2, 25, by = 1))

knn_fit <- train(
  auction_tot ~ ., 
  data = training_data, 
  method = "knn", 
  trControl = sampling_strat, 
  tuneGrid = hyper_grid,
  metric = "RMSE"
)
    
ggplot(knn_fit)
# k = 2 has the lowest RMSE
# RMSE is 1776

library(caret)

# Train the KNN model with the chosen k value
k <- 2
knn_model <- train(
  auction_tot ~ .,
  data = training_data,
  method = "knn",
  trControl = sampling_strat,
  tuneGrid = data.frame(k = k),
  metric = "accuracy"
)
knn_model # RMSE is 2471

# Make predictions on the testing data
predictions <- predict(knn_model, newdata = testing_data)



```

# random forest
```{r}
library(ranger)

dim(merged_df)
n_features <- length(setdiff(names(training_data), "auction_tot"))

# train a default random forest model
training_rf <- ranger(
  auction_tot ~ ., 
  data = training_data,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  importance= "permutation",
  seed = 123
)
training_rf
default_rmse <- sqrt(training_rf$prediction.error) # RMSE: 759
rf_importance <- ranger::importance(training_rf)
sort(rf_importance, decreasing = TRUE)

# lowering RMSE

# parameter grid
parameter_grid <- expand.grid(
  mtry = c(floor(n_features / 3)),
  num.trees = c(50, 100, 200),
  min.node.size = c(1, 5, 10)
)

results <- lapply(1:nrow(parameter_grid), function(i) {
  model <- ranger(
    auction_tot ~ .,
    data = training_data,
    num.trees = parameter_grid$num.trees[i],
    mtry = parameter_grid$mtry[i],
    min.node.size = parameter_grid$min.node.size[i],
    respect.unordered.factors = "order",
    importance = "permutation",
    seed = 123
  )
  predictions <- predict(model, data = testing_data)$predictions
  rmse <- sqrt(mean((predictions - testing_data$auction_tot)^2))
  list(model = model, rmse = rmse)
})

best_model_index <- which.min(sapply(results, function(x) x$rmse))
best_model <- results[[best_model_index]]$model

predictions <- predict(best_model, data = testing_data)$predictions
rmse_rf <- sqrt(mean((predictions - testing_data$auction_tot)^2)) # RMSE:584


```

